{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_japanese(string):\n",
    "    for chr in string:\n",
    "        try:\n",
    "            name = unicodedata.name(ch)\n",
    "            if \"CJK UNIFIED\" in name or \"HIRAGANA\" in name or \"KATAKANA\" in name:\n",
    "                return true\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "def RMSLE(x : np.ndarray, y : np.ndarray):\n",
    "    x_log = np.log(x + 1)\n",
    "    y_log = np.log(y + 1)\n",
    "    mse = ((x_log - y_log)**2).sum() / len(y)\n",
    "    rmsle = np.sqrt(mse)\n",
    "    \n",
    "    return rmsle\n",
    "\n",
    "def new_category(x):\n",
    "    if x in [1, 30, 43, 44, 10, 20, 24]:\n",
    "        return 1\n",
    "    elif x in [26, 27, 28]:\n",
    "        return 2\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def relate_category(x):\n",
    "    if x in [30, 43, 44]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def judge_channel_over_100(x):\n",
    "    if x in [\"ANNnewsCH\", \"Khan Academy\", \"Khan Academy\", \"TED\", \"UNIVERSAL MUSIC JAPAN\", \"avex\"]:\n",
    "        return x\n",
    "    else:\n",
    "        return \"others\"\n",
    "    \n",
    "def is_insta_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_insta = (bool(re.search(\"insta\", x)) or bool(re.search(\"インスタ\", x)))\n",
    "    return is_insta\n",
    "\n",
    "def is_twitter_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_twitter = (bool(re.search(\"twitter\", x)) or bool(re.search(\"ツイッター\", x)))\n",
    "    return is_twitter\n",
    "\n",
    "def is_facebook_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_facebook = (bool(re.search(\"facebook\", x)) or bool(re.search(\"フェイスブック\", x)))\n",
    "    return is_facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNan(df):\n",
    "    df[\"tags\"].fillna(\"[none]\", inplace=True)\n",
    "    df[\"description\"].fillna(\" \", inplace=True)\n",
    "    df[\"title\"].fillna(\" \", inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def boolToInt(df):\n",
    "    df[\"comments_disabled\"] = df[\"comments_disabled\"].astype(np.int16)\n",
    "    df[\"ratings_disabled\"] = df[\"ratings_disabled\"].astype(np.int16)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def logarize(df):\n",
    "    df[\"log_likes\"] = np.log(df[\"likes\"] + 1)\n",
    "    df[\"log_dislikes\"] = np.log(df[\"dislikes\"] + 1)\n",
    "    df[\"log_comment_count\"] = np.log(df[\"comment_count\"] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def likes_dislikes_ratio(df):\n",
    "    df[\"likes_dislikes_ratio\"] = df[\"likes\"] / (df[\"dislikes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_likes_ratio(df):\n",
    "    df[\"comments_likes_ratio\"] = df[\"comment_count\"] / (df[\"likes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_dislikes_ratio(df):\n",
    "    df[\"comments_dislikes_ratio\"] = df[\"comment_count\"] / (df[\"dislikes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def likes_comments_disabled(df):\n",
    "    df[\"likes_comments_disabled\"] = np.log(df[\"likes\"] * df[\"comments_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def dislikes_commentes_diabled(df):\n",
    "    df[\"dislikes_comments_disabled\"] = np.log(df[\"likes\"] * df[\"comments_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_ratings_diabled(df):\n",
    "    df[\"comments_ratings_diabled\"] = np.log(df[\"comment_count\"] * df[\"ratings_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def getTagDetail(df):\n",
    "    df[\"num_tags\"] = df[\"tags\"].astype(str).apply(lambda x : len(x.split(\"|\")))\n",
    "    df[\"length_tags\"] = df[\"tags\"].astype(str).apply(lambda x : len(x))\n",
    "    df[\"tags_point\"] = df[\"tags\"].apply(lambda x : sum([bool(re.search(\"[a-zA-Z0-9]\", px)) for px in x.split(\"|\")])) # ??\n",
    "    df[\"count_en_tag\"] = df[\"tags\"].apply(lambda x : sum([bool(re.search(\"[a-zA-Z0-9]\", px)) for px in x.split(\"|\")]))\n",
    "    df[\"count_ja_tag\"] = df[\"tags\"].apply(lambda x : sum([is_japanese(px) for px in x.split(\"|\")]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getPublishedAtDetail(df):\n",
    "    df[\"publishedAt\"] = pd.to_datetime(df[\"publishedAt\"], utc=True)\n",
    "    df[\"publishedAt_year\"] = df[\"publishedAt\"].apply(lambda x: x.year)\n",
    "    df[\"publishedAt_month\"] = df[\"publishedAt\"].apply(lambda x: x.month)\n",
    "    df[\"publishedAt_day\"] = df[\"publishedAt\"].apply(lambda x: x.day)\n",
    "    df[\"publishedAt_hour\"] = df[\"publishedAt\"].apply(lambda x: x.hour)\n",
    "    df[\"publishedAt_minute\"] = df[\"publishedAt\"].apply(lambda x: x.minute)\n",
    "    df[\"publishedAt_second\"] = df[\"publishedAt\"].apply(lambda x: x.second)\n",
    "    df[\"publishedAt_dayofweek\"] = df[\"publishedAt\"].apply(lambda x: x.dayofweek)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getColletction_dateDetail(df):\n",
    "    df[\"collection_date\"] = pd.to_datetime(\"20\"+df[\"collection_date\"].astype(str), format=\"%Y.%d.%m\", utc=True)\n",
    "    df[\"collection_date_year\"] = df[\"collection_date\"].apply(lambda x : x.year)\n",
    "    df[\"collection_date_month\"] = df[\"collection_date\"].apply(lambda x : x.month)\n",
    "    df[\"collection_date_day\"] = df[\"collection_date\"].apply(lambda x : x.day)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def delta(df):\n",
    "    df[\"delta\"] = (df[\"collection_date\"] - df[\"publishedAt\"]).apply(lambda x: x.days)\n",
    "    df[\"logdelta\"] = np.log(df[\"delta\"])\n",
    "    #df[\"sqrtdelta\"] = np.sqrt(df[\"delta\"])\n",
    "    df[\"published_delta\"] = (df[\"publishedAt\"] - df[\"publishedAt\"].min()).apply(lambda x: x.days)\n",
    "    df[\"collection_delta\"] = (df[\"collection_date\"] - df[\"collection_date\"].min()).apply(lambda x: x.days)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getDescriptionDetail(df):\n",
    "    df[\"is_http_in_dis\"] = df[\"description\"].astype(str).apply(lambda x: x.lower().count(\"http\"))\n",
    "    df[\"len_description\"] = df[\"description\"].astype(str).apply(lambda x: len(x))\n",
    "    #df[\"is_insta_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_insta_in_description(x)) #\n",
    "    #df[\"is_twitter_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_twitter_in_description(x))\n",
    "    df[\"is_insta_in_dis\"] = df[\"description\"].apply(lambda x : x.lower().count(\"insta\"))\n",
    "    df[\"is_twitter_in_dis\"] = df[\"description\"].apply(lambda x : x.lower().count(\"twitter\"))\n",
    "    #df[\"is_facebook_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_facebook_in_description(x))\n",
    "    return df\n",
    "\n",
    "def lenTitle(df):\n",
    "    df[\"len_title\"] = df[\"title\"].apply(lambda x : len(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def confirmJapanese(df):\n",
    "    df[\"ja_title\"] = df[\"title\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    df[\"ja_tags\"] = df[\"tags\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    df[\"ja_description\"] = df[\"description\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def countEnglish(df):\n",
    "    df[\"en_title\"] = df[\"title\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    df[\"en_tags\"] = df[\"tags\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    df[\"en_description\"] = df[\"description\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getMusic(df):\n",
    "    df[\"music_title\"] = df[\"title\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    df[\"music_tags\"] = df[\"tags\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    df[\"music_description\"] = df[\"description\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def confirmOfficial(df):\n",
    "    df[\"is_off\"] = df[\"title\"].apply(lambda x: \"fficial\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_channell\"] = df[\"channelTitle\"].apply(lambda x: \"fficial\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_ja\"] = df[\"title\"].apply(lambda x: \"公式\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_channell_ja\"] = df[\"channelTitle\"].apply(lambda x: \"公式\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getCM(df):\n",
    "    df[\"cm_title\"] = df[\"title\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    df[\"cm_tags\"] = df[\"tags\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    df[\"cm_description\"] = df[\"description\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_dummies_from_category(df):\n",
    "    #df[\"new_category\"] = df[\"categoryId\"].apply(lambda x : new_category(x))\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"categoryId\"])], axis=1)\n",
    "    del df[\"categoryId\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_num_channel_over_100(df):\n",
    "    df[\"channelTitle\"] = df[\"channelTitle\"].apply(lambda x : judge_channel_over_100(x))\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"channelTitle\"])], axis=1)\n",
    "    return df\n",
    "\n",
    "def judge_categoryId_over_30(df):\n",
    "    df[\"categoryId_over_30\"] = df[\"categoryId\"].apply(lambda x : 1 if x >= 30 else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19720, 18)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_data.csv\")\n",
    "test = pd.read_csv(\"data/test_data.csv\")\n",
    "train[\"thumbnail_path\"] = [str(x) for x in sorted(train_path.glob(\"image*\"))]\n",
    "test[\"thumbnail_path\"] = [str(x) for x in sorted(test_path.glob(\"image*\"))]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.51490740740741 37.51490740740741\n",
      "0 0\n",
      "(90, 120) (90, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x128285cd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(\"thumbnail/train/image_00009.jpeg\")\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "print(hls[..., 1].mean(), hls[..., 1].mean())\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.threshold(gray,15, 255, cv2.THRESH_BINARY)[1]\n",
    "print(gray[0,0], img2[0,0])\n",
    "print(gray.shape, img2.shape)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_satu(x):\n",
    "    img = cv2.imread(x)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    l = img[..., 1].mean()\n",
    "    return l\n",
    "\n",
    "def get_light(x):\n",
    "    img = cv2.imread(x)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    s = img[..., 2].mean()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saturation_and_lightness(df):\n",
    "    df[\"saturation\"] = df[\"thumbnail_path\"].apply(lambda x : get_satu(x))\n",
    "    df[\"lightness\"] = df[\"thumbnail_path\"].apply(lambda x : get_light(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, df_test, methods):\n",
    "    for method in methods:\n",
    "        df = method(df)\n",
    "        df_test = method(df_test)\n",
    "    \n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original(df):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's rmse: 0.903321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 0.964878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[789]\tvalid_0's rmse: 0.877797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid_0's rmse: 0.882067\n",
      "Feature :  original\n",
      "Test RMSLE : 0.9065605657817009±0.0012224490802946284\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's rmse: 0.89997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid_0's rmse: 0.964309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[723]\tvalid_0's rmse: 0.878854\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1019]\tvalid_0's rmse: 0.887872\n",
      "Feature :  likes_dislikes_ratio\n",
      "Test RMSLE : 0.9073001982773835±0.0011344735340935858\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's rmse: 0.900786\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\tvalid_0's rmse: 0.964512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[673]\tvalid_0's rmse: 0.876791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's rmse: 0.881367\n",
      "Feature :  comments_likes_ratio\n",
      "Test RMSLE : 0.9054168091599561±0.001240316647655861\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's rmse: 0.901449\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[550]\tvalid_0's rmse: 0.963091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[874]\tvalid_0's rmse: 0.879014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[995]\tvalid_0's rmse: 0.880987\n",
      "Feature :  comments_dislikes_ratio\n",
      "Test RMSLE : 0.9056850350866388±0.0011705183007851185\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[700]\tvalid_0's rmse: 0.903735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 0.964002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[629]\tvalid_0's rmse: 0.879824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[936]\tvalid_0's rmse: 0.882252\n",
      "Feature :  likes_comments_disabled\n",
      "Test RMSLE : 0.9070104187566351±0.0011644343988107377\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[700]\tvalid_0's rmse: 0.903735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 0.964002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[629]\tvalid_0's rmse: 0.879824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[936]\tvalid_0's rmse: 0.882252\n",
      "Feature :  dislikes_commentes_diabled\n",
      "Test RMSLE : 0.9070104187566351±0.0011644343988107377\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\tvalid_0's rmse: 0.90136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid_0's rmse: 0.964838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[738]\tvalid_0's rmse: 0.878456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1251]\tvalid_0's rmse: 0.880866\n",
      "Feature :  comments_ratings_diabled\n",
      "Test RMSLE : 0.9059345212225386±0.001230384069691777\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1334]\tvalid_0's rmse: 0.875359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1072]\tvalid_0's rmse: 0.9423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's rmse: 0.858029\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1588]\tvalid_0's rmse: 0.863669\n",
      "Feature :  getTagDetail\n",
      "Test RMSLE : 0.884406064595451±0.001150755990926236\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[551]\tvalid_0's rmse: 0.89789\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[885]\tvalid_0's rmse: 0.968597\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[593]\tvalid_0's rmse: 0.87288\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's rmse: 0.87975\n",
      "Feature :  delta\n",
      "Test RMSLE : 0.9043233688070584±0.0014551574531626635\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1053]\tvalid_0's rmse: 0.900537\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[538]\tvalid_0's rmse: 0.955215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[828]\tvalid_0's rmse: 0.881215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[961]\tvalid_0's rmse: 0.870655\n",
      "Feature :  getDescriptionDetail\n",
      "Test RMSLE : 0.9014587459488523±0.0010725096271856245\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[584]\tvalid_0's rmse: 0.904166\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[496]\tvalid_0's rmse: 0.96778\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[844]\tvalid_0's rmse: 0.878222\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1547]\tvalid_0's rmse: 0.8722\n",
      "Feature :  lenTitle\n",
      "Test RMSLE : 0.9051386382585773±0.0014461423400942126\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's rmse: 0.903321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 0.964878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[789]\tvalid_0's rmse: 0.877797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid_0's rmse: 0.882067\n",
      "Feature :  confirmJapanese\n",
      "Test RMSLE : 0.9065605657817009±0.0012224490802946284\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1116]\tvalid_0's rmse: 0.874647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1144]\tvalid_0's rmse: 0.948337\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[770]\tvalid_0's rmse: 0.864225\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1292]\tvalid_0's rmse: 0.849979\n",
      "Feature :  countEnglish\n",
      "Test RMSLE : 0.883846538792093±0.0014539721761783096\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[742]\tvalid_0's rmse: 0.898499\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[513]\tvalid_0's rmse: 0.964406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[769]\tvalid_0's rmse: 0.874902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1043]\tvalid_0's rmse: 0.872451\n",
      "Feature :  getMusic\n",
      "Test RMSLE : 0.9021124548475746±0.0013908717007505727\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[554]\tvalid_0's rmse: 0.900578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[587]\tvalid_0's rmse: 0.961764\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid_0's rmse: 0.874087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[913]\tvalid_0's rmse: 0.871456\n",
      "Feature :  confirmOfficial\n",
      "Test RMSLE : 0.901515943413413±0.0013343865678908532\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's rmse: 0.902691\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's rmse: 0.965508\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[931]\tvalid_0's rmse: 0.878457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[942]\tvalid_0's rmse: 0.883553\n",
      "Feature :  getCM\n",
      "Test RMSLE : 0.9070962745235941±0.0012141531242126906\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[664]\tvalid_0's rmse: 0.888129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's rmse: 0.963967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[699]\tvalid_0's rmse: 0.87214\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[848]\tvalid_0's rmse: 0.883254\n",
      "Feature :  get_dummies_from_category\n",
      "Test RMSLE : 0.901429513332205±0.0013306795705222494\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\tvalid_0's rmse: 0.901913\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[540]\tvalid_0's rmse: 0.9658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[603]\tvalid_0's rmse: 0.878738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1046]\tvalid_0's rmse: 0.877685\n",
      "Feature :  get_num_channel_over_100\n",
      "Test RMSLE : 0.9055907799126803±0.0012961631562609917\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's rmse: 0.903321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 0.964878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[789]\tvalid_0's rmse: 0.877797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid_0's rmse: 0.882067\n",
      "Feature :  judge_categoryId_over_30\n",
      "Test RMSLE : 0.9065605657817009±0.0012224490802946284\n",
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[496]\tvalid_0's rmse: 0.897325\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[541]\tvalid_0's rmse: 0.95247\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[721]\tvalid_0's rmse: 0.876008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1025]\tvalid_0's rmse: 0.883999\n",
      "Feature :  get_saturation_and_lightness\n",
      "Test RMSLE : 0.9019895179133987±0.0009034579915088842\n"
     ]
    }
   ],
   "source": [
    "ever = [fillNan, logarize, boolToInt, getPublishedAtDetail, getColletction_dateDetail]\n",
    "results = []\n",
    "for x in [original, likes_dislikes_ratio,\n",
    "     comments_likes_ratio,\n",
    "     comments_dislikes_ratio,\n",
    "     likes_comments_disabled,\n",
    "     dislikes_commentes_diabled,\n",
    "     comments_ratings_diabled,\n",
    "     getTagDetail,\n",
    "     delta,\n",
    "     getDescriptionDetail,\n",
    "     lenTitle,\n",
    "     confirmJapanese,\n",
    "     countEnglish,\n",
    "     getMusic,\n",
    "     confirmOfficial,\n",
    "     getCM,\n",
    "     get_dummies_from_category,\n",
    "     get_num_channel_over_100,\n",
    "     judge_categoryId_over_30,\n",
    "     get_saturation_and_lightness\n",
    "    ]:\n",
    "    train = pd.read_csv(\"data/train_data.csv\")\n",
    "    test = pd.read_csv(\"data/test_data.csv\")\n",
    "    train_path = Path(\"thumbnail/train\")\n",
    "    test_path = Path(\"thumbnail/test\")\n",
    "\n",
    "    train[\"thumbnail_path\"] = [str(x) for x in sorted(train_path.glob(\"image*\"))]\n",
    "    test[\"thumbnail_path\"] = [str(x) for x in sorted(test_path.glob(\"image*\"))]\n",
    "    temp = ever + [x]\n",
    "    train, test = preprocessing(\n",
    "        train, \n",
    "        test, \n",
    "        temp\n",
    "    )\n",
    "    idx = []\n",
    "    for column in train.columns:\n",
    "        if column in [\"y\", \"likes\", \"dislikes\", \"comment_count\", \n",
    "                      \"delta\", \"channelId\", \"video_id\", \"title\",\n",
    "                      \"description\", \"thumbnail_link\", \n",
    "                      \"tags\", \"publishedAt\", \"collection_date\", \"id\", \"channelTitle\", \"thumbnail_path\"]:#, \"categoryId\"]:\n",
    "            continue\n",
    "        idx.append(column)\n",
    "\n",
    "    X = train.loc[:, idx].values\n",
    "    Y = np.log(train.loc[:, \"y\"]).values\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "    x_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "    \n",
    "    K = 4\n",
    "\n",
    "    print(\"K = \", K)\n",
    "    kf = KFold(n_splits = K, shuffle=True, random_state=42).split(x_train, y_train)\n",
    "    gbm = [None] * K\n",
    "    scores = []\n",
    "    scores_test = []\n",
    "    for i, (train_idx, test_idx) in enumerate(kf):\n",
    "        x_train = X[train_idx]\n",
    "        y_train = Y[train_idx]\n",
    "        x_test = X[test_idx]\n",
    "        y_test = Y[test_idx]\n",
    "\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "        # LightGBM parameters\n",
    "        params = {\n",
    "                'task' : 'train',\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective' : 'regression',\n",
    "                'metric' : \"rmse\",\n",
    "                'num_leaves' : 32,\n",
    "                'learning_rate' : 0.01,\n",
    "                #'feature_fraction' : 0.9,\n",
    "                #'bagging_fraction' : 0.8,\n",
    "                #'bagging_freq': 5,\n",
    "                'random_state' : 42\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        # train\n",
    "        gbm[i] = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=lgb_test,\n",
    "            early_stopping_rounds=100, \n",
    "            verbose_eval=10000\n",
    "        )\n",
    "\n",
    "\n",
    "        y_pred = gbm[i].predict(x_test, num_iteration=gbm[i].best_iteration)\n",
    "        y_pred = np.exp(y_pred).astype(int)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        rmsle_test = RMSLE(y_pred, np.exp(y_test))\n",
    "\n",
    "        scores_test.append(rmsle_test)\n",
    "\n",
    "    print(\"Feature : \", x.__name__)\n",
    "    print(\"Test RMSLE : {}±{}\".format(np.mean(scores_test), np.var(scores_test)))\n",
    "    results.append((x.__name__, np.mean(scores_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countEnglish', 0.883846538792093),\n",
       " ('getTagDetail', 0.884406064595451),\n",
       " ('get_dummies_from_category', 0.901429513332205),\n",
       " ('getDescriptionDetail', 0.9014587459488523),\n",
       " ('confirmOfficial', 0.901515943413413),\n",
       " ('get_saturation_and_lightness', 0.9019895179133987),\n",
       " ('getMusic', 0.9021124548475746),\n",
       " ('delta', 0.9043233688070584),\n",
       " ('lenTitle', 0.9051386382585773),\n",
       " ('comments_likes_ratio', 0.9054168091599561),\n",
       " ('get_num_channel_over_100', 0.9055907799126803),\n",
       " ('comments_dislikes_ratio', 0.9056850350866388),\n",
       " ('comments_ratings_diabled', 0.9059345212225386),\n",
       " ('original', 0.9065605657817009),\n",
       " ('confirmJapanese', 0.9065605657817009),\n",
       " ('judge_categoryId_over_30', 0.9065605657817009),\n",
       " ('likes_comments_disabled', 0.9070104187566351),\n",
       " ('dislikes_commentes_diabled', 0.9070104187566351),\n",
       " ('getCM', 0.9070962745235941),\n",
       " ('likes_dislikes_ratio', 0.9073001982773835)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19720, 18)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_data.csv\")\n",
    "test = pd.read_csv(\"data/test_data.csv\")\n",
    "train[\"thumbnail_path\"] = [str(x) for x in sorted(train_path.glob(\"image*\"))]\n",
    "test[\"thumbnail_path\"] = [str(x) for x in sorted(test_path.glob(\"image*\"))]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocessing(\n",
    "    train, \n",
    "    test, \n",
    "    [fillNan, \n",
    "     logarize, \n",
    "     boolToInt,\n",
    "     likes_dislikes_ratio,\n",
    "     comments_likes_ratio,\n",
    "     comments_dislikes_ratio,\n",
    "     likes_comments_disabled,\n",
    "     dislikes_commentes_diabled,\n",
    "     comments_ratings_diabled,\n",
    "     getTagDetail,\n",
    "     getPublishedAtDetail,\n",
    "     getColletction_dateDetail,\n",
    "     delta,\n",
    "     getDescriptionDetail,\n",
    "     lenTitle,\n",
    "     confirmJapanese,\n",
    "     countEnglish,\n",
    "     getMusic,\n",
    "     confirmOfficial,\n",
    "     getCM,\n",
    "     #get_dummies_from_category,\n",
    "     get_num_channel_over_100,\n",
    "     #judge_categoryId_over_30\n",
    "     get_saturation_and_lightness\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category ID, カテゴリへの関連付け  \n",
    "1 : Film and animation 1   \n",
    "2 : Autos and vehicles 1   \n",
    "10 : Music 1   \n",
    "15 : Pets and animals 1   \n",
    "17 : Sports 1   \n",
    "19 : Travel and events 1   \n",
    "20 : Gaming 1   \n",
    "22 : People and blogs 1   \n",
    "23 : Comedy 1   \n",
    "24 : Entertainment 1   \n",
    "25 : News and politics 1   \n",
    "26 : Howto and style 1   \n",
    "27 : Education 1   \n",
    "28 : Science and technology 1   \n",
    "29 : ?  \n",
    "30 : Movies 0   \n",
    "43 : Shows（番組）0   \n",
    "44 : Trailers（予告編）0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies, entertaiments 1 - 30 - 43 - 44 - (10) - (20) -(24)  \n",
    "Vhehicles 2  \n",
    "Sounds 10  \n",
    "Animals 15  \n",
    "Sports 17  \n",
    "Travels 19  \n",
    "Games 20  \n",
    "Blogs : 22 - 26  \n",
    "Politics : 25  \n",
    "Howto : 26  \n",
    "Study : (26) - 27 - 28  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx :  ['categoryId', 'comments_disabled', 'ratings_disabled', 'log_likes', 'log_dislikes', 'log_comment_count', 'likes_dislikes_ratio', 'comments_likes_ratio', 'comments_dislikes_ratio', 'likes_comments_disabled', 'dislikes_comments_disabled', 'comments_ratings_diabled', 'num_tags', 'length_tags', 'tags_point', 'count_en_tag', 'count_ja_tag', 'publishedAt_year', 'publishedAt_month', 'publishedAt_day', 'publishedAt_hour', 'publishedAt_minute', 'publishedAt_second', 'publishedAt_dayofweek', 'collection_date_year', 'collection_date_month', 'collection_date_day', 'logdelta', 'published_delta', 'collection_delta', 'is_http_in_dis', 'len_description', 'is_insta_in_dis', 'is_twitter_in_dis', 'len_title', 'ja_title', 'ja_tags', 'ja_description', 'en_title', 'en_tags', 'en_description', 'music_title', 'music_tags', 'music_description', 'is_off', 'is_off_channell', 'is_off_ja', 'is_off_channell_ja', 'cm_title', 'cm_tags', 'cm_description', 'ANNnewsCH', 'Khan Academy', 'TED', 'UNIVERSAL MUSIC JAPAN', 'avex', 'others', 'saturation', 'lightness']\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for column in train.columns:\n",
    "    if column in [\"y\", \"likes\", \"dislikes\", \"comment_count\", \n",
    "                  \"delta\", \"channelId\", \"video_id\", \"title\",\n",
    "                  \"description\", \"thumbnail_link\", \n",
    "                  \"tags\", \"publishedAt\", \"collection_date\", \"id\", \"channelTitle\", \"thumbnail_path\"]:#, \"categoryId\"]:\n",
    "        continue\n",
    "    idx.append(column)\n",
    "print(\"idx : \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape :  (19720, 59)\n"
     ]
    }
   ],
   "source": [
    "X = train.loc[:, idx].values\n",
    "Y = np.log(train.loc[:, \"y\"]).values\n",
    "\n",
    "print(\"X shape : \", X.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "x_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Build a model and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1429]\tvalid_0's rmse: 0.853877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[777]\tvalid_0's rmse: 0.936109\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[846]\tvalid_0's rmse: 0.852569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1249]\tvalid_0's rmse: 0.830073\n",
      "Test RMSLE : 0.8677066011965021±0.0016375868903321916\n"
     ]
    }
   ],
   "source": [
    "K = 4\n",
    "\n",
    "print(\"K = \", K)\n",
    "kf = KFold(n_splits = K, shuffle=True, random_state=42).split(x_train, y_train)\n",
    "gbm = [None] * K\n",
    "scores = []\n",
    "scores_test = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    x_train = X[train_idx]\n",
    "    y_train = Y[train_idx]\n",
    "    x_test = X[test_idx]\n",
    "    y_test = Y[test_idx]\n",
    "   \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : \"rmse\",\n",
    "            'num_leaves' : 32,\n",
    "            'learning_rate' : 0.01,\n",
    "            #'feature_fraction' : 0.9,\n",
    "            #'bagging_fraction' : 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "            'random_state' : 42\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm[i] = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_test,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=10000\n",
    "    )\n",
    "\n",
    "\n",
    "    y_pred = gbm[i].predict(x_test, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_test = RMSLE(y_pred, np.exp(y_test))\n",
    "\n",
    "    scores_test.append(rmsle_test)\n",
    "\n",
    "\n",
    "print(\"Test RMSLE : {}±{}\".format(np.mean(scores_test), np.var(scores_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provisual best score : 0.870526493774021±0.0016966648056599104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let model learn with Kfold and predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  11\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2357]\tvalid_0's rmse: 0.819823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1743]\tvalid_0's rmse: 0.840169\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3964]\tvalid_0's rmse: 0.785365\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1783]\tvalid_0's rmse: 0.854713\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3241]\tvalid_0's rmse: 0.785131\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1882]\tvalid_0's rmse: 0.776847\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3104]\tvalid_0's rmse: 0.805596\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2568]\tvalid_0's rmse: 0.805422\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3697]\tvalid_0's rmse: 0.794427\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3059]\tvalid_0's rmse: 0.766816\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3407]\tvalid_0's rmse: 0.765414\n",
      "Training RMSLE :0.5132450408536816±0.002306089254696093 \n",
      "Test RMSLE : 0.7993605300259605±0.0007585632744967617\n"
     ]
    }
   ],
   "source": [
    "K = 11\n",
    "\n",
    "print(\"K = \", K)\n",
    "kf = KFold(n_splits = K, shuffle=True, random_state=42).split(X, Y)\n",
    "gbm = [None] * K\n",
    "scores = []\n",
    "scores_test = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    x_train = X[train_idx]\n",
    "    y_train = Y[train_idx]\n",
    "    x_test = X[test_idx]\n",
    "    y_test = Y[test_idx]\n",
    "   \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : \"rmse\",\n",
    "            'num_leaves' : 32,\n",
    "            'learning_rate' : 0.01,\n",
    "            #'feature_fraction' : 0.9,\n",
    "            #'bagging_fraction' : 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "            'random_state' : 42\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm[i] = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_test,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=10000\n",
    "    )\n",
    "\n",
    "    y_pred = gbm[i].predict(x_train, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_train = RMSLE(y_pred, np.exp(y_train))\n",
    "    y_pred = gbm[i].predict(x_test, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_test = RMSLE(y_pred, np.exp(y_test))\n",
    "\n",
    "    scores.append(rmsle_train)\n",
    "    scores_test.append(rmsle_test)\n",
    "\n",
    "\n",
    "print(\"Training RMSLE :{}±{} \".format(np.mean(scores), np.var(scores)))\n",
    "print(\"Test RMSLE : {}±{}\".format(np.mean(scores_test), np.var(scores_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test.loc[:, idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 11\n",
    "y_pred = np.array([0.] * len(t))\n",
    "for x in range(K):\n",
    "    pred = gbm[x].predict(t, num_iteration=gbm[x].best_iteration)\n",
    "    pred = np.exp(pred)\n",
    "    pred[pred < 0] = 0\n",
    "    y_pred += pred\n",
    "    \n",
    "\n",
    "y_pred = (y_pred / K).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([list(range(1, len(y_pred)+1)), y_pred]).T\n",
    "df_submit = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\"id\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>244632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2800871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>901836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>163040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        y\n",
       "0   1   244632\n",
       "1   2  2800871\n",
       "2   3   901836\n",
       "3   4   163040\n",
       "4   5      259"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"submit_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
