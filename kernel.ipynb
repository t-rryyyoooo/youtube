{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_japanese(string):\n",
    "    for chr in string:\n",
    "        try:\n",
    "            name = unicodedata.name(ch)\n",
    "            if \"CJK UNIFIED\" in name or \"HIRAGANA\" in name or \"KATAKANA\" in name:\n",
    "                return true\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "def RMSLE(x : np.ndarray, y : np.ndarray):\n",
    "    x_log = np.log(x + 1)\n",
    "    y_log = np.log(y + 1)\n",
    "    mse = ((x_log - y_log)**2).sum() / len(y)\n",
    "    rmsle = np.sqrt(mse)\n",
    "    \n",
    "    return rmsle\n",
    "\n",
    "def new_category(x):\n",
    "    if x in [1, 30, 43, 44, 10, 20, 24]:\n",
    "        return 1\n",
    "    elif x in [26, 27, 28]:\n",
    "        return 2\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def relate_category(x):\n",
    "    if x in [30, 43, 44]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def judge_channel_over_100(x):\n",
    "    if x in [\"ANNnewsCH\", \"Khan Academy\", \"Khan Academy\", \"TED\", \"UNIVERSAL MUSIC JAPAN\", \"avex\"]:\n",
    "        return x\n",
    "    else:\n",
    "        return \"others\"\n",
    "    \n",
    "def is_insta_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_insta = (bool(re.search(\"insta\", x)) or bool(re.search(\"インスタ\", x)))\n",
    "    return is_insta\n",
    "\n",
    "def is_twitter_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_twitter = (bool(re.search(\"twitter\", x)) or bool(re.search(\"ツイッター\", x)))\n",
    "    return is_twitter\n",
    "\n",
    "def is_facebook_in_description(x):\n",
    "    x = x.lower()\n",
    "    is_facebook = (bool(re.search(\"facebook\", x)) or bool(re.search(\"フェイスブック\", x)))\n",
    "    return is_facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNan(df):\n",
    "    df[\"tags\"].fillna(\"[none]\", inplace=True)\n",
    "    df[\"description\"].fillna(\" \", inplace=True)\n",
    "    df[\"title\"].fillna(\" \", inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def boolToInt(df):\n",
    "    df[\"comments_disabled\"] = df[\"comments_disabled\"].astype(np.int16)\n",
    "    df[\"ratings_disabled\"] = df[\"ratings_disabled\"].astype(np.int16)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def logarize(df):\n",
    "    df[\"log_likes\"] = np.log(df[\"likes\"] + 1)\n",
    "    df[\"log_dislikes\"] = np.log(df[\"dislikes\"] + 1)\n",
    "    df[\"log_comment_count\"] = np.log(df[\"comment_count\"] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def likes_dislikes_ratio(df):\n",
    "    df[\"likes_dislikes_ratio\"] = df[\"likes\"] / (df[\"dislikes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_likes_ratio(df):\n",
    "    df[\"comments_likes_ratio\"] = df[\"comment_count\"] / (df[\"likes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_dislikes_ratio(df):\n",
    "    df[\"comments_dislikes_ratio\"] = df[\"comment_count\"] / (df[\"dislikes\"] + 1)\n",
    "    return df\n",
    "\n",
    "def likes_comments_disabled(df):\n",
    "    df[\"likes_comments_disabled\"] = np.log(df[\"likes\"] * df[\"comments_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def dislikes_commentes_diabled(df):\n",
    "    df[\"dislikes_comments_disabled\"] = np.log(df[\"likes\"] * df[\"comments_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def comments_ratings_diabled(df):\n",
    "    df[\"comments_ratings_diabled\"] = np.log(df[\"comment_count\"] * df[\"ratings_disabled\"] + 1)\n",
    "    return df\n",
    "\n",
    "def getTagDetail(df):\n",
    "    df[\"num_tags\"] = df[\"tags\"].astype(str).apply(lambda x : len(x.split(\"|\")))\n",
    "    df[\"length_tags\"] = df[\"tags\"].astype(str).apply(lambda x : len(x))\n",
    "    df[\"tags_point\"] = df[\"tags\"].apply(lambda x : sum([bool(re.search(\"[a-zA-Z0-9]\", px)) for px in x.split(\"|\")])) # ??\n",
    "    df[\"count_en_tag\"] = df[\"tags\"].apply(lambda x : sum([bool(re.search(\"[a-zA-Z0-9]\", px)) for px in x.split(\"|\")]))\n",
    "    df[\"count_ja_tag\"] = df[\"tags\"].apply(lambda x : sum([is_japanese(px) for px in x.split(\"|\")]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getPublishedAtDetail(df):\n",
    "    df[\"publishedAt\"] = pd.to_datetime(df[\"publishedAt\"], utc=True)\n",
    "    df[\"publishedAt_year\"] = df[\"publishedAt\"].apply(lambda x: x.year)\n",
    "    df[\"publishedAt_month\"] = df[\"publishedAt\"].apply(lambda x: x.month)\n",
    "    df[\"publishedAt_day\"] = df[\"publishedAt\"].apply(lambda x: x.day)\n",
    "    df[\"publishedAt_hour\"] = df[\"publishedAt\"].apply(lambda x: x.hour)\n",
    "    df[\"publishedAt_minute\"] = df[\"publishedAt\"].apply(lambda x: x.minute)\n",
    "    df[\"publishedAt_second\"] = df[\"publishedAt\"].apply(lambda x: x.second)\n",
    "    df[\"publishedAt_dayofweek\"] = df[\"publishedAt\"].apply(lambda x: x.dayofweek)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getColletction_dateDetail(df):\n",
    "    df[\"collection_date\"] = pd.to_datetime(\"20\"+df[\"collection_date\"].astype(str), format=\"%Y.%d.%m\", utc=True)\n",
    "    df[\"collection_date_year\"] = df[\"collection_date\"].apply(lambda x : x.year)\n",
    "    df[\"collection_date_month\"] = df[\"collection_date\"].apply(lambda x : x.month)\n",
    "    df[\"collection_date_day\"] = df[\"collection_date\"].apply(lambda x : x.day)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def delta(df):\n",
    "    df[\"delta\"] = (df[\"collection_date\"] - df[\"publishedAt\"]).apply(lambda x: x.days)\n",
    "    df[\"logdelta\"] = np.log(df[\"delta\"])\n",
    "    #df[\"sqrtdelta\"] = np.sqrt(df[\"delta\"])\n",
    "    df[\"published_delta\"] = (df[\"publishedAt\"] - df[\"publishedAt\"].min()).apply(lambda x: x.days)\n",
    "    df[\"collection_delta\"] = (df[\"collection_date\"] - df[\"collection_date\"].min()).apply(lambda x: x.days)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getDescriptionDetail(df):\n",
    "    df[\"is_http_in_dis\"] = df[\"description\"].astype(str).apply(lambda x: x.lower().count(\"http\"))\n",
    "    df[\"len_description\"] = df[\"description\"].astype(str).apply(lambda x: len(x))\n",
    "    #df[\"is_insta_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_insta_in_description(x)) #\n",
    "    #df[\"is_twitter_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_twitter_in_description(x))\n",
    "    df[\"is_insta_in_dis\"] = df[\"description\"].apply(lambda x : x.lower().count(\"insta\"))\n",
    "    df[\"is_twitter_in_dis\"] = df[\"description\"].apply(lambda x : x.lower().count(\"twitter\"))\n",
    "    #df[\"is_facebook_in_dis\"] = df[\"description\"].astype(str).apply(lambda x : is_facebook_in_description(x))\n",
    "    return df\n",
    "\n",
    "def lenTitle(df):\n",
    "    df[\"len_title\"] = df[\"title\"].apply(lambda x : len(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def confirmJapanese(df):\n",
    "    df[\"ja_title\"] = df[\"title\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    df[\"ja_tags\"] = df[\"tags\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    df[\"ja_description\"] = df[\"description\"].apply(lambda x: is_japanese(x)).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def countEnglish(df):\n",
    "    df[\"en_title\"] = df[\"title\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    df[\"en_tags\"] = df[\"tags\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    df[\"en_description\"] = df[\"description\"].apply(lambda x: len(re.findall(r'[a-zA-Z0-9]', x.lower())))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getMusic(df):\n",
    "    df[\"music_title\"] = df[\"title\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    df[\"music_tags\"] = df[\"tags\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    df[\"music_description\"] = df[\"description\"].apply(lambda x: \"music\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def confirmOfficial(df):\n",
    "    df[\"is_off\"] = df[\"title\"].apply(lambda x: \"fficial\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_channell\"] = df[\"channelTitle\"].apply(lambda x: \"fficial\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_ja\"] = df[\"title\"].apply(lambda x: \"公式\" in x.lower()).astype(np.int)\n",
    "    df[\"is_off_channell_ja\"] = df[\"channelTitle\"].apply(lambda x: \"公式\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getCM(df):\n",
    "    df[\"cm_title\"] = df[\"title\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    df[\"cm_tags\"] = df[\"tags\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    df[\"cm_description\"] = df[\"description\"].apply(lambda x: \"cm\" in x.lower()).astype(np.int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_dummies_from_category(df):\n",
    "    #df[\"new_category\"] = df[\"categoryId\"].apply(lambda x : new_category(x))\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"categoryId\"])], axis=1)\n",
    "    del df[\"categoryId\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_num_channel_over_100(df):\n",
    "    df[\"channelTitle\"] = df[\"channelTitle\"].apply(lambda x : judge_channel_over_100(x))\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"channelTitle\"])], axis=1)\n",
    "    return df\n",
    "\n",
    "def judge_categoryId_over_30(df):\n",
    "    df[\"categoryId_over_30\"] = df[\"categoryId\"].apply(lambda x : 1 if x >= 30 else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19720, 17)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_data.csv\")\n",
    "test = pd.read_csv(\"data/test_data.csv\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, df_test, methods):\n",
    "    for method in methods:\n",
    "        df = method(df)\n",
    "        df_test = method(df_test)\n",
    "    \n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocessing(\n",
    "    train, \n",
    "    test, \n",
    "    [fillNan, \n",
    "     logarize, \n",
    "     boolToInt,\n",
    "     likes_dislikes_ratio,\n",
    "     comments_likes_ratio,\n",
    "     comments_dislikes_ratio,\n",
    "     likes_comments_disabled,\n",
    "     dislikes_commentes_diabled,\n",
    "     comments_ratings_diabled,\n",
    "     getTagDetail,\n",
    "     getPublishedAtDetail,\n",
    "     getColletction_dateDetail,\n",
    "     delta,\n",
    "     getDescriptionDetail,\n",
    "     lenTitle,\n",
    "     confirmJapanese,\n",
    "     countEnglish,\n",
    "     getMusic,\n",
    "     confirmOfficial,\n",
    "     getCM,\n",
    "     #get_dummies_from_category,\n",
    "     get_num_channel_over_100,\n",
    "     #judge_categoryId_over_30\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category ID, カテゴリへの関連付け  \n",
    "1 : Film and animation 1   \n",
    "2 : Autos and vehicles 1   \n",
    "10 : Music 1   \n",
    "15 : Pets and animals 1   \n",
    "17 : Sports 1   \n",
    "19 : Travel and events 1   \n",
    "20 : Gaming 1   \n",
    "22 : People and blogs 1   \n",
    "23 : Comedy 1   \n",
    "24 : Entertainment 1   \n",
    "25 : News and politics 1   \n",
    "26 : Howto and style 1   \n",
    "27 : Education 1   \n",
    "28 : Science and technology 1   \n",
    "29 : ?  \n",
    "30 : Movies 0   \n",
    "43 : Shows（番組）0   \n",
    "44 : Trailers（予告編）0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies, entertaiments 1 - 30 - 43 - 44 - (10) - (20) -(24)  \n",
    "Vhehicles 2  \n",
    "Sounds 10  \n",
    "Animals 15  \n",
    "Sports 17  \n",
    "Travels 19  \n",
    "Games 20  \n",
    "Blogs : 22 - 26  \n",
    "Politics : 25  \n",
    "Howto : 26  \n",
    "Study : (26) - 27 - 28  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx :  ['categoryId', 'comments_disabled', 'ratings_disabled', 'log_likes', 'log_dislikes', 'log_comment_count', 'likes_dislikes_ratio', 'comments_likes_ratio', 'comments_dislikes_ratio', 'likes_comments_disabled', 'dislikes_comments_disabled', 'comments_ratings_diabled', 'num_tags', 'length_tags', 'tags_point', 'count_en_tag', 'count_ja_tag', 'publishedAt_year', 'publishedAt_month', 'publishedAt_day', 'publishedAt_hour', 'publishedAt_minute', 'publishedAt_second', 'publishedAt_dayofweek', 'collection_date_year', 'collection_date_month', 'collection_date_day', 'logdelta', 'published_delta', 'collection_delta', 'is_http_in_dis', 'len_description', 'is_insta_in_dis', 'is_twitter_in_dis', 'len_title', 'ja_title', 'ja_tags', 'ja_description', 'en_title', 'en_tags', 'en_description', 'music_title', 'music_tags', 'music_description', 'is_off', 'is_off_channell', 'is_off_ja', 'is_off_channell_ja', 'cm_title', 'cm_tags', 'cm_description', 'ANNnewsCH', 'Khan Academy', 'TED', 'UNIVERSAL MUSIC JAPAN', 'avex', 'others']\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for column in train.columns:\n",
    "    if column in [\"y\", \"likes\", \"dislikes\", \"comment_count\", \n",
    "                  \"delta\", \"channelId\", \"video_id\", \"title\",\n",
    "                  \"description\", \"thumbnail_link\", \n",
    "                  \"tags\", \"publishedAt\", \"collection_date\", \"id\", \"channelTitle\"]:#, \"categoryId\"]:\n",
    "        continue\n",
    "    idx.append(column)\n",
    "print(\"idx : \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape :  (19720, 57)\n"
     ]
    }
   ],
   "source": [
    "X = train.loc[:, idx].values\n",
    "Y = np.log(train.loc[:, \"y\"]).values\n",
    "\n",
    "print(\"X shape : \", X.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "x_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Build a model and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1403]\tvalid_0's rmse: 0.854798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1180]\tvalid_0's rmse: 0.934997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[857]\tvalid_0's rmse: 0.853014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2335]\tvalid_0's rmse: 0.82975\n",
      "Test RMSLE : 0.8677254918926922±0.0015941995790084965\n"
     ]
    }
   ],
   "source": [
    "K = 4\n",
    "\n",
    "print(\"K = \", K)\n",
    "kf = KFold(n_splits = K, shuffle=True, random_state=42).split(x_train, y_train)\n",
    "gbm = [None] * K\n",
    "scores = []\n",
    "scores_test = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    x_train = X[train_idx]\n",
    "    y_train = Y[train_idx]\n",
    "    x_test = X[test_idx]\n",
    "    y_test = Y[test_idx]\n",
    "   \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : \"rmse\",\n",
    "            'num_leaves' : 32,\n",
    "            'learning_rate' : 0.01,\n",
    "            #'feature_fraction' : 0.9,\n",
    "            #'bagging_fraction' : 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "            'random_state' : 42\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm[i] = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_test,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=10000\n",
    "    )\n",
    "\n",
    "\n",
    "    y_pred = gbm[i].predict(x_test, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_test = RMSLE(y_pred, np.exp(y_test))\n",
    "\n",
    "    scores_test.append(rmsle_test)\n",
    "\n",
    "\n",
    "print(\"Test RMSLE : {}±{}\".format(np.mean(scores_test), np.var(scores_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provisual best score : 0.8166593973772355±0.0007880495387959792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let model learn with Kfold and predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  11\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2932]\tvalid_0's rmse: 0.82372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1605]\tvalid_0's rmse: 0.852365\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2476]\tvalid_0's rmse: 0.793982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2059]\tvalid_0's rmse: 0.858234\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2134]\tvalid_0's rmse: 0.791149\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1923]\tvalid_0's rmse: 0.774793\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2849]\tvalid_0's rmse: 0.80341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2449]\tvalid_0's rmse: 0.809579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3912]\tvalid_0's rmse: 0.786738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2717]\tvalid_0's rmse: 0.769929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2743]\tvalid_0's rmse: 0.767556\n",
      "Training RMSLE :0.5385149382167732±0.0013593089933693263 \n",
      "Test RMSLE : 0.8022519243581093±0.0008709580985751859\n"
     ]
    }
   ],
   "source": [
    "K = 11\n",
    "\n",
    "print(\"K = \", K)\n",
    "kf = KFold(n_splits = K, shuffle=True, random_state=42).split(X, Y)\n",
    "gbm = [None] * K\n",
    "scores = []\n",
    "scores_test = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    x_train = X[train_idx]\n",
    "    y_train = Y[train_idx]\n",
    "    x_test = X[test_idx]\n",
    "    y_test = Y[test_idx]\n",
    "   \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : \"rmse\",\n",
    "            'num_leaves' : 32,\n",
    "            'learning_rate' : 0.01,\n",
    "            #'feature_fraction' : 0.9,\n",
    "            #'bagging_fraction' : 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "            'random_state' : 42\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm[i] = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_test,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=10000\n",
    "    )\n",
    "\n",
    "    y_pred = gbm[i].predict(x_train, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_train = RMSLE(y_pred, np.exp(y_train))\n",
    "    y_pred = gbm[i].predict(x_test, num_iteration=gbm[i].best_iteration)\n",
    "    y_pred = np.exp(y_pred).astype(int)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    rmsle_test = RMSLE(y_pred, np.exp(y_test))\n",
    "\n",
    "    scores.append(rmsle_train)\n",
    "    scores_test.append(rmsle_test)\n",
    "\n",
    "\n",
    "print(\"Training RMSLE :{}±{} \".format(np.mean(scores), np.var(scores)))\n",
    "print(\"Test RMSLE : {}±{}\".format(np.mean(scores_test), np.var(scores_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test.loc[:, idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 11\n",
    "y_pred = np.array([0.] * len(t))\n",
    "for x in range(K):\n",
    "    pred = gbm[x].predict(t, num_iteration=gbm[x].best_iteration)\n",
    "    pred = np.exp(pred)\n",
    "    pred[pred < 0] = 0\n",
    "    y_pred += pred\n",
    "    \n",
    "\n",
    "y_pred = (y_pred / K).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([list(range(1, len(y_pred)+1)), y_pred]).T\n",
    "df_submit = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\"id\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>257234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2622811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>886744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>163382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        y\n",
       "0   1   257234\n",
       "1   2  2622811\n",
       "2   3   886744\n",
       "3   4   163382\n",
       "4   5      251"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"submit_7.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
